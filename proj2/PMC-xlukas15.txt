Architektury Výpočetních Systémů (AVS 2024)
Projekt č. 2 (PMC)
Login: xlukas15

Úloha 1: Paralelizace původního řešení
===============================================================================
1) Kterou ze smyček (viz zadání) je vhodnější paralelizovat a co způsobuje 
   neefektivitu paralelizaci té druhé?
   
   Pro paralelizaci jsem si vybral smyčku v metodě marchCubes (tedy tu první).
   První smyčka se totiž nachází v nejvyšší úrovni.
   Volá se v ní metoda buildCube, která teprve pak volá evaluateFieldAt (je volaná 8krát pro každé spuštění buildCube).
   Bylo by tedy neefektivní ji mít ve druhé smyčce, protože by se zbytečně často zakládala a rušila nová vlákna.

2) Jak jste ve funkci LoopMeshBuilder::marchCubes zajistili správný výsledek 
  (počet trojúhelníků) vrácený touto funkcí? Popište jaké řešení jste zvolili a proč.  
  
   Zajistil jsem to pomocí OpenMP redukce na proměnné totalTriangles (reduction(+: totalTriangles)).
   Díky tomu vždy dostanu správný součet na konci smyčky, protože redukce umožňuje souběžně přistupovat k datům (v mém případě k totalTriangles).

3) Jaké plánování (rozdělení práce mezi vlákna) jste zvolili a proč? Popište, na
   jakých datech (počet vláken, velikost problému) jste k závěrům došli.  

   Zvolil jsem si plánování schedule(guided, 8).
   Různé typy plánování jsem zkoušel na souboru bun_zipper_res3.pts s --grid 128 a úlohu jsem spouštěl pro 18 a 36 vláken.
   Pro různá plánování a velikosti jsem spustil 20 iterací, z nichž právě guided, 8 mi vyšla nejlépe.
   Nicméně velmi podobně vyšla i třeba dynamic, 8.
   Výsledné plánování jsem vybral na základě dosažených časů (avg 18 vláken: 492 ms, avg 36 vláken: 312 ms).

Úloha 2: Paralelní průchod stromem
===============================================================================
1) Stručně popište použití OpenMP tasků ve vašem řešení. 

   OpenMP tasky používám v metodě processNode, kdy je ve smyčce for každý uzel rozdělen na 8 dalších potomků.
   Pro každého z těchto potomků pak spouštím vlastní task, který opět rekurzivně vytváří další potomky.
   Následně tasky synchronizuji pomocí pragmy taskwait.
   To způsobí, že všechny poduzly budou dokončeny předtím, než je vrácen výsledek.
   V každém z tasku je nastavena množina sdílených zdrojů (pos, childGridSize...) a soukromých zdrojů (i).
   Aktualizace počtu trojúhelníků je pak docílena pomocí pragmy atomic pro update, kterou se předchází race condition.

2) Jakou hodnotu cut-off jste zvolili? Jaké hodnoty "cut-off" jste zkoušeli, 
   na jak velkých velikostech problému a jakých času jste dosáhli? 
   Odůvodněte vaši volbu.

   Jako cut-off jsem zvolil hodnotu 1.
   Zkoušel jsem ale i jiné mocniny základu 2, tedy například 2, 4, 8.
   Testoval jsem to na grid velikostech 64 a 128, tedy stejně, jako je to ve scriptu compare.sh.
   Zároveň jsou zkoušel program spouštět na 18 a 36 vláken.
   S velikostí cut-offu se časy výrazně snižovaly.
   Nicméně jelikož model se zvětšujícím se cut-offem neměl tolik polygonů, byl model více roztroušený a nevypadal celistvě.
   Níže uvádím, jaké časy mi průměrně vycházely pro různé velikosti cut-offu pro 18 a 36 vláken na souboru bun_zipper_res3.pts s --grid 128.

      - cut-off = 1 => threads 18:   198 ms   threads 36: 162 ms
      - cut-off = 2 => threads 18:    27 ms   threads 36:  23 ms
      - cut-off = 4 => threads 18:     4 ms   threads 36:   4 ms
      - cut-off = 8 => threads 18:     1 ms   threads 36:   2 ms

   Cut-off 1 jsem zvolil z důvodu přesnosti. Při vysokém cut-offu model neobsahuje tolik trojúhelníků, díky čemuž také neprochází porovnávacím skriptem. 

3) Jakým způsobem zajišťujete ukládání trojúhelníků z několika vláken současně 
   v metodě LoopMeshBuilder::emitTriangle?

   Ve variantě loop i tree ukládám trojúhelníky za pomoci kritické sekce.
   To způsobuje, že dovnitř může přistoupit pouze jedno vlákno v jeden okamžik, díky čemuž nemůže vzniknout race condition.
   Využívám tedy pragmu #pragma omp critical, která mi umožňuje bezpečně přistupovat k pomocnému vektoru mTriangles.

Úloha 3: Grafy škálování všech řešení
===============================================================================

1) Stručně zhodnoťte efektivitu vytvořených řešení 
   (na základě VŠECH odevzdaných grafů ŠKÁLOVÁNÍ).

   Z grafů škálování je zřejmé, že celkově efektivnější je spíše implementace s octree, a to primárně pro větší mřížky.
   
   U silného škálování si lze všimnout, že efektivita octree při velkém počtu vláken má trend spíše klesat (při malém množství vstupů na vlákno).
   Tento problém nejspíše způsobuje velká režie pro správu a synchronizaci paralelizace.

   Při slabém škálování je zajímavé si všímat loop implementace.
   Jeho výkon je totiž víceméně konstantní i s roustoucí velikostí vstupu na vlákno.
   Při velkých vstupech je vidět trend, při kterém má loop velmi podobnou efektivitu, jako octree.

   Na grafu, týkajícím se velikostí mřížky opět jasně vyniká octree, který se loopu s roustoucí velikostí vstupu neustále více vzdaluje.

2) V jakém případě (v závislosti na počtu bodů ve vstupním souboru a velikosti 
   mřížky) bude vaše řešení 1. úlohy neefektivní? 
   (pokud takový případ existuje a je vidět ve vašem grafu)

   Octree bude neefektivní v případech, ve kterých je velikost mřížky velká, ale počet bodů ve vstupním souboru malý.
   Lze si toho všimnout na grafech silného škálování, kde při vysokém počtu vláken a malém množství vstupů na vlákno dochází ke snižování efektivity.
   To je zřejmě způsobeno velkou režií při vytváření a synchronizaci vláken.

3) Je (nebo není) stromový algoritmus efektivnější z pohledu slabého škálování 
   vzhledem ke vstupu?

   Octree efektivnější spíše není.
   Při rostoucím počtu vláken totiž čas výpočtu roste, což je zřejmě způsobeno vysokou režíí, správou a synchronizací tasků.
   Loop ale bez ohledu na množství vláken zůstává znatelně konzistentnější i se zvyšujícím se počtem vláken.

4) Do souboru 3_4.txt napište svůj login, který používáte na Barboře, na druhý
   řádek napište počet úloh (jobs), které jste spustili za dobu řešení projektu 2
   a na třetí řádek uveďte, kolik času tyto úlohy běžely (formát HH:MM:SS). 
   V souboru 3_4.txt využijte předpřipravené kostry - údaje přepište. Můžete využít
   údajů ze Slurm plánovače, nepočítejte úlohy se suffixem (přepínač -X).

   xlukas15
   50
   08:44:17

Úloha 4: Analýza využití jader pomocí VTune
================================================================================

1) Jaké bylo průměrné využití jader pro všechny tři implementace s omezením na 
   18 vláken? Hodnoty zapište do souboru 4_1.txt
   (využijte předpřipravené kostry v souboru - čísla přepište).
   
   ref:  0.992
   loop: 16.534
   tree: 12.915

2) Jaké bylo průměrné využití jader pro všechny tři implementace s využitím 
   všech jader? Hodnoty zapište do souboru 4_2.txt (využijte předpřipravené 
   kostry v souboru - čísla přepište).
   
   ref:  0.995
   loop: 30.932
   tree: 19.660

3) Vypočítejte efektivitu vašeho řešení loop a tree vůči ref pro 18 a 36 vláken. 
   Hodnoty naměřte ručně na výpočetním uzlu, ne přes VTune. Použijte následující parametry:
   
   ./PMC --builder {ref, tree, loop} -t {18, 36} --grid 128 ../data/bun_zipper_res3.pts 
   
   Hodnoty zapište do souboru 4_3.txt 
   (využijte předpřipravené kostry v souboru - čísla přepište):
   "loop (18)" vs. "ref"   106.553 %
   "tree (18)" vs. "ref"   262.367 %
   "loop (36)" vs. "ref"    80.325 %
   "tree (36)" vs. "ref"    60.430 %

   Poznámka:   Testovaný binární soubor byl vytvořen slurm skriptem vtune.sl.
               Spouštění PMC bylo provedeno s použitím kompilátoru intel-compilers/2024.2.0, tedy stejným, jako používá vtune.sl.

   Poznámka:   Efektivitu jsem počítal stejně, jako na cvičení 5.
               Tedy např. pro loop (18) jsem počítal jako ref(18)/loop(18) = SPEEDUP.
               Potom SPEEDUP/18*100 = EFEKTIVITA
